{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5e529f",
   "metadata": {},
   "source": [
    "## import library and load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0471de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pyswarms as ps\n",
    "from deap import base, creator, tools, algorithms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e66de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number Train: 614\n",
      "Row Number Test: 367\n",
      "Columns :\n",
      "['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Applicant_Income', 'Coapplicant_Income', 'Loan_Amount', 'Term', 'Credit_History', 'Area', 'Status']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('loan_train.csv')\n",
    "test_df = pd.read_csv('loan_test.csv')\n",
    "\n",
    "print(f\"Row Number Train: {train_df.shape[0]}\")\n",
    "print(f\"Row Number Test: {test_df.shape[0]}\")\n",
    "print(f\"Columns :\\n{train_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019fd18a",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98d521c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    \"\"\"\n",
    "    Data Preprocessing:\n",
    "    1. NAN Delete\n",
    "    2. Converting nominal variables to numeric with LabelEncoder\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy Data\n",
    "    train = train_data.copy()\n",
    "    test = test_data.copy()\n",
    "    \n",
    "    print(f\"\\n Number of NaN before deletion:\")\n",
    "    print(train.isnull().sum())\n",
    "    \n",
    "    # Delete rows with NaN\n",
    "    \n",
    "    train_clean = train.dropna()\n",
    "    test_clean = test.dropna()\n",
    "    \n",
    "    \n",
    "    # Nominal columns to be converted\n",
    "    categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Area', 'Status']\n",
    "    \n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in train_clean.columns:\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # for Train\n",
    "            train_clean[col] = le.fit_transform(train_clean[col].astype(str))\n",
    "            \n",
    "            # for test\n",
    "            \n",
    "            if col in test_clean.columns:\n",
    "                # Use learned_classes on train\n",
    "                # If it is a new value, it will be converted to NaN\n",
    "                test_clean[col] = test_clean[col].map(\n",
    "                    lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else -1\n",
    "                )\n",
    "                \n",
    "                label_encoders[col] = le\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"{col} mapping: {mapping}\")\n",
    "                \n",
    "    if 'Dependents' in train_clean.columns:\n",
    "        train_clean['Dependents'] = train_clean['Dependents'].replace('3+', '3').astype(float)\n",
    "    if 'Dependents' in test_clean.columns:\n",
    "        test_clean['Dependents'] = test_clean['Dependents'].replace('3+', '3').astype(float)\n",
    "    return train_clean, test_clean, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f46bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of NaN before deletion:\n",
      "Gender                13\n",
      "Married                3\n",
      "Dependents            15\n",
      "Education              0\n",
      "Self_Employed         32\n",
      "Applicant_Income       0\n",
      "Coapplicant_Income     0\n",
      "Loan_Amount            0\n",
      "Term                  14\n",
      "Credit_History        50\n",
      "Area                   0\n",
      "Status                 0\n",
      "dtype: int64\n",
      "Gender mapping: {'Female': np.int64(0), 'Male': np.int64(1)}\n",
      "Married mapping: {'No': np.int64(0), 'Yes': np.int64(1)}\n",
      "Education mapping: {'Graduate': np.int64(0), 'Not Graduate': np.int64(1)}\n",
      "Self_Employed mapping: {'No': np.int64(0), 'Yes': np.int64(1)}\n",
      "Area mapping: {'Rural': np.int64(0), 'Semiurban': np.int64(1), 'Urban': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "train_processed, test_processed, encoders = preprocess_data(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1df2bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and labels\n",
    "\n",
    "X_train = train_processed.drop('Status', axis=1)\n",
    "y_train = train_processed['Status']\n",
    "\n",
    "if 'Status' in test_processed.columns:\n",
    "    X_test = test_processed.drop('Status', axis=1)\n",
    "    y_test = test_processed['Status']\n",
    "else:\n",
    "    X_test = test_processed.copy()\n",
    "    y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "551d4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready for model:\n",
      "X_train shape: (499, 11)\n",
      "y_train shape: (499,)\n",
      "X_test shape: (293, 11)\n",
      "  0: Gender\n",
      "  1: Married\n",
      "  2: Dependents\n",
      "  3: Education\n",
      "  4: Self_Employed\n",
      "  5: Applicant_Income\n",
      "  6: Coapplicant_Income\n",
      "  7: Loan_Amount\n",
      "  8: Term\n",
      "  9: Credit_History\n",
      "  10: Area\n",
      "\n",
      " Label distribution:\n",
      "Status\n",
      "1    341\n",
      "0    158\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Data ready for model:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    print(f\"  {i}: {col}\")\n",
    "\n",
    "print(f\"\\n Label distribution:\")\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aabee72",
   "metadata": {},
   "source": [
    "## PSO implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b8f0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSO_FeatureSelection:\n",
    "    \"\"\"\n",
    "    Feature selection using PSO algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, alpha=0.99):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.alpha = alpha\n",
    "        self.n_features = X_train.shape[1]\n",
    "        \n",
    "        self.fitness_history = []\n",
    "        self.best_fitness_history = []\n",
    "        self.selected_features_history = []\n",
    "        \n",
    "    def fitness_function(self, particles):\n",
    "        \"\"\"\n",
    "        Fitness function for PSO\n",
    "\n",
    "        J = α(1 - Acc) + (1 - α)(1 - n_selected/n_total)\n",
    "\n",
    "        Objective: Minimize J (which is equivalent to maximizing \n",
    "        accuracy and minimizing the number of features)\n",
    "        \"\"\"\n",
    "        fitness_values = []\n",
    "        \n",
    "        for particle in particles:\n",
    "        # Convert to binary (threshold = 0.5)\n",
    "            binary_particle = (particle > 0.5).astype(int)\n",
    "            \n",
    "            # If no features are selected, give bad fitness\n",
    "            if binary_particle.sum() == 0:\n",
    "                fitness_values.append(1.0)\n",
    "                continue\n",
    "            \n",
    "            # Select features\n",
    "            selected_indices = np.where(binary_particle == 1)[0]\n",
    "            X_train_selected = self.X_train.iloc[:, selected_indices]\n",
    "            X_test_selected = self.X_test.iloc[:, selected_indices]\n",
    "            \n",
    "            # Training the Random Forest model\n",
    "            rf = RandomForestClassifier(n_estimators=50, random_state=33, n_jobs=-1)\n",
    "            rf.fit(X_train_selected, self.y_train)\n",
    "            \n",
    "            # Calculation accuracy\n",
    "            y_pred = rf.predict(X_test_selected)\n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            \n",
    "            # Calculate the ratio of selected features\n",
    "            feature_ratio = binary_particle.sum() / self.n_features\n",
    "            \n",
    "            # Calculate the fitness function\n",
    "            fitness = self.alpha * (1 - accuracy) + (1 - self.alpha) * feature_ratio\n",
    "            \n",
    "            fitness_values.append(fitness)\n",
    "        \n",
    "        return np.array(fitness_values)\n",
    "    \n",
    "    def optimize(self, n_particles=50, n_iterations=100, verbose=True):\n",
    "        \"\"\"\n",
    "        Implementing the PSO algorithm\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_particles: number of particles\n",
    "        n_iterations: Number of iterations\n",
    "        verbose: show progress\n",
    "        \"\"\"\n",
    " \n",
    "        print(f\"Number of particles: {n_particles}\")\n",
    "        print(f\"Number of repetitions: {n_iterations}\")\n",
    "        print(f\"Number of features: {self.n_features}\")\n",
    "        print(f\"Alpha (accuracy weight): {self.alpha}\")\n",
    "        \n",
    "        # PSO Setting\n",
    "        options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
    "        \n",
    "        # Create optimizer\n",
    "        optimizer = ps.single.GlobalBestPSO(\n",
    "            n_particles=n_particles,\n",
    "            dimensions=self.n_features,\n",
    "            options=options,\n",
    "            bounds=(np.zeros(self.n_features), np.ones(self.n_features))\n",
    "        )\n",
    "        \n",
    "        # Optimization\n",
    "        best_cost, best_pos = optimizer.optimize(\n",
    "            self.fitness_function,\n",
    "            iters=n_iterations,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        self.fitness_history = optimizer.cost_history\n",
    "        \n",
    "        # Convert best position to binary\n",
    "        best_features = (best_pos > 0.5).astype(int)\n",
    "        selected_indices = np.where(best_features == 1)[0]\n",
    "        \n",
    "        # Calculating the final accuracy\n",
    "        X_train_selected = self.X_train.iloc[:, selected_indices]\n",
    "        X_test_selected = self.X_test.iloc[:, selected_indices]\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train_selected, self.y_train)\n",
    "        y_pred = rf.predict(X_test_selected)\n",
    "        final_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "\n",
    "        print(f\" Best Fitness: {best_cost:.6f}\")\n",
    "        print(f\"Ultimate accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "        print(f\"Number of selected features: {len(selected_indices)}/{self.n_features}\")\n",
    "        print(f\"\\nSelected features:\")\n",
    "        for idx in selected_indices:\n",
    "            print(f\"{self.X_train.columns[idx]}\")\n",
    "        \n",
    "        return {\n",
    "            'best_features': best_features,\n",
    "            'selected_indices': selected_indices,\n",
    "            'selected_feature_names': self.X_train.columns[selected_indices].tolist(),\n",
    "            'best_fitness': best_cost,\n",
    "            'final_accuracy': final_accuracy,\n",
    "            'n_selected': len(selected_indices),\n",
    "            'fitness_history': self.fitness_history\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aadac8",
   "metadata": {},
   "source": [
    "***Run PSO***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3179d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-01 19:17:51,736 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of particles: 50\n",
      "Number of repetitions: 100\n",
      "Number of features: 11\n",
      "Alpha (accuracy weight): 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best:   0%|          |0/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████|100/100, best_cost=0.177\n",
      "2026-02-01 19:30:21,985 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.17705454545454546, best pos: [0.54886542 0.15871635 0.44566087 0.35927389 0.44676989 0.74753723\n",
      " 0.41529876 0.76168335 0.6984333  0.70222312 0.60061875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Fitness: 0.177055\n",
      "Ultimate accuracy: 0.8133 (81.33%)\n",
      "Number of selected features: 6/11\n",
      "\n",
      "Selected features:\n",
      "Gender\n",
      "Applicant_Income\n",
      "Loan_Amount\n",
      "Term\n",
      "Credit_History\n",
      "Area\n"
     ]
    }
   ],
   "source": [
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=33)\n",
    "pso_selector = PSO_FeatureSelection(\n",
    "    X_train_, y_train_, X_val, y_val, alpha=0.99\n",
    ")\n",
    "\n",
    "pso_results = pso_selector.optimize(\n",
    "    n_particles=50,\n",
    "    n_iterations=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642bc24d",
   "metadata": {},
   "source": [
    "## GA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a016b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_FeatureSelection:\n",
    "    \"\"\"\n",
    "    Feature selection using Genetic Algorithm (GA)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, alpha=0.99):\n",
    " \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.alpha = alpha\n",
    "        self.n_features = X_train.shape[1]\n",
    "        \n",
    "        self.fitness_history = []\n",
    "        self.best_fitness_history = []\n",
    "        \n",
    "    def evaluate_individual(self, individual):\n",
    "        \"\"\"\n",
    "        Evaluation of a person\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "        fitness: tuple with one element (for DEAP)\n",
    "        \"\"\"\n",
    "        # Convert to numpy array\n",
    "        selected_features = np.array(individual)\n",
    "        \n",
    "        # If no feature is selected\n",
    "        if selected_features.sum() == 0:\n",
    "            return (1.0,) \n",
    "        \n",
    "        # Select features\n",
    "        selected_indices = np.where(selected_features == 1)[0]\n",
    "        X_train_selected = self.X_train.iloc[:, selected_indices]\n",
    "        X_test_selected = self.X_test.iloc[:, selected_indices]\n",
    "        \n",
    "        # Model training\n",
    "        rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train_selected, self.y_train)\n",
    "        \n",
    "        # predict and calculating accuracy\n",
    "        y_pred = rf.predict(X_test_selected)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "        # Calculating the feature ratio\n",
    "        feature_ratio = selected_features.sum() / self.n_features\n",
    "        \n",
    "        # Fitness calculation\n",
    "        fitness = self.alpha * (1 - accuracy) + (1 - self.alpha) * feature_ratio\n",
    "        \n",
    "        return (fitness,)\n",
    "    \n",
    "    def optimize(self, pop_size=50, n_generations=50, cx_prob=0.7, mut_prob=0.2, verbose=True):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pop_size: Population size\n",
    "        n_generations: Number of generations\n",
    "        cx_prob: Crossover probability\n",
    "        mut_prob: Mutation probability\n",
    "        verbose: Show progress\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"Population size: {pop_size}\")\n",
    "        print(f\"Number of generations: {n_generations}\")\n",
    "        print(f\"Crossover probability: {cx_prob}\")\n",
    "        print(f\"Mutation probability: {mut_prob}\")\n",
    "        print(f\"Number of features: {self.n_features}\")\n",
    "        print(f\"Alpha (accuracy weight): {self.alpha}\")\n",
    "        \n",
    "        # DEAP Setting\n",
    "        if hasattr(creator, \"FitnessMin\"):\n",
    "            del creator.FitnessMin\n",
    "        if hasattr(creator, \"Individual\"):\n",
    "            del creator.Individual\n",
    "            \n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        # Gene creation (0 or 1)\n",
    "        toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
    "        \n",
    "        # Create Person\n",
    "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
    "                        toolbox.attr_bool, n=self.n_features)\n",
    "        \n",
    "        # Create a crowd\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        \n",
    "        # Register operators\n",
    "        toolbox.register(\"evaluate\", self.evaluate_individual)\n",
    "        toolbox.register(\"mate\", tools.cxTwoPoint)  # Two-Point Crossover\n",
    "        toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)  # Bit Flip Mutation\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        # Create the initial population\n",
    "        population = toolbox.population(n=pop_size)\n",
    "        \n",
    "        # Statistics\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"min\", np.min)\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        # Hall of Fame \n",
    "        hof = tools.HallOfFame(1)\n",
    "        \n",
    "        # Run the algorithm\n",
    "        for gen in range(n_generations):\n",
    "            # Population assessment\n",
    "            fitnesses = list(map(toolbox.evaluate, population))\n",
    "            for ind, fit in zip(population, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "            \n",
    "            # Save statistics\n",
    "            record = stats.compile(population)\n",
    "            self.fitness_history.append(record['min'])\n",
    "            \n",
    "            # Show progress\n",
    "            # if verbose and (gen % 10 == 0 or gen == n_generations - 1):\n",
    "            #     print(f\"نسل {gen+1:3d}/{n_generations} | \"\n",
    "            #           f\"Best Fitness: {record['min']:.6f} | \"\n",
    "            #           f\"Avg: {record['avg']:.6f}\")\n",
    "            \n",
    "            # Hall of Fame Update\n",
    "            hof.update(population)\n",
    "            \n",
    "            # select\n",
    "            offspring = toolbox.select(population, len(population))\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "            \n",
    "            # Crossover\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if np.random.random() < cx_prob:\n",
    "                    toolbox.mate(child1, child2)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "            \n",
    "            # Mutation\n",
    "            for mutant in offspring:\n",
    "                if np.random.random() < mut_prob:\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "            \n",
    "            # Replacement\n",
    "            population[:] = offspring\n",
    "        \n",
    "        # The best person\n",
    "        best_individual = hof[0]\n",
    "        best_features = np.array(best_individual)\n",
    "        selected_indices = np.where(best_features == 1)[0]\n",
    "        \n",
    "        # Calculating the final accuracy\n",
    "        X_train_selected = self.X_train.iloc[:, selected_indices]\n",
    "        X_test_selected = self.X_test.iloc[:, selected_indices]\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        rf.fit(X_train_selected, self.y_train)\n",
    "        y_pred = rf.predict(X_test_selected)\n",
    "        final_accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "\n",
    "        print(f\"Best Fitness: {best_individual.fitness.values[0]:.6f}\")\n",
    "        print(f\"Final Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "        print(f\"Number of selected features: {len(selected_indices)}/{self.n_features}\")\n",
    "        print(f\"\\n Selected features:\")\n",
    "        for idx in selected_indices:\n",
    "            print(f\"{self.X_train.columns[idx]}\")\n",
    "\n",
    "        \n",
    "        return {\n",
    "            'best_features': best_features,\n",
    "            'selected_indices': selected_indices,\n",
    "            'selected_feature_names': self.X_train.columns[selected_indices].tolist(),\n",
    "            'best_fitness': best_individual.fitness.values[0],\n",
    "            'final_accuracy': final_accuracy,\n",
    "            'n_selected': len(selected_indices),\n",
    "            'fitness_history': self.fitness_history\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2166d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population size: 50\n",
      "Number of generations: 50\n",
      "Crossover probability: 0.9\n",
      "Mutation probability: 0.1\n",
      "Number of features: 11\n",
      "Alpha (accuracy weight): 0.99\n",
      "Best Fitness: 0.192073\n",
      "Final Accuracy: 0.7933 (79.33%)\n",
      "Number of selected features: 8/11\n",
      "\n",
      " Selected features:\n",
      "Gender\n",
      "Married\n",
      "Dependents\n",
      "Education\n",
      "Applicant_Income\n",
      "Loan_Amount\n",
      "Term\n",
      "Credit_History\n"
     ]
    }
   ],
   "source": [
    "# اجرای GA\n",
    "ga_selector = GA_FeatureSelection(\n",
    "    X_train_, y_train_, X_val, y_val, alpha=0.99\n",
    ")\n",
    "\n",
    "ga_results = ga_selector.optimize(\n",
    "    pop_size=50,\n",
    "    n_generations=50,\n",
    "    cx_prob=0.9,\n",
    "    mut_prob=0.1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1651d",
   "metadata": {},
   "source": [
    "## Comparison of PSO and GA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8eae2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Criteria      PSO       GA\n",
      "         Final Accuracy (%)    81.33    79.33\n",
      "Number of Features Selected     6/11     8/11\n",
      "Feature Reduction Ratio (%)    45.45    27.27\n",
      "               Best Fitness 0.177055 0.192073\n",
      "      Number of Repetitions      100       50\n",
      "PSO has better accuracy (Difference: 2.00%)\n",
      "PSO created a simpler model (2 fewer features)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_algorithms(pso_results, ga_results, feature_names):\n",
    "    \"\"\"\n",
    "   Full comparison of PSO and GA results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Comparison table\n",
    "    comparison_data = {\n",
    "        'Criteria': [\n",
    "        'Final Accuracy (%)',\n",
    "        'Number of Features Selected',\n",
    "        'Feature Reduction Ratio (%)',\n",
    "        'Best Fitness',\n",
    "        'Number of Repetitions'\n",
    "        ],\n",
    "        'PSO': [\n",
    "            f\"{pso_results['final_accuracy']*100:.2f}\",\n",
    "            f\"{pso_results['n_selected']}/{len(feature_names)}\",\n",
    "            f\"{(1 - pso_results['n_selected']/len(feature_names))*100:.2f}\",\n",
    "            f\"{pso_results['best_fitness']:.6f}\",\n",
    "            len(pso_results['fitness_history'])\n",
    "        ],\n",
    "        'GA': [\n",
    "            f\"{ga_results['final_accuracy']*100:.2f}\",\n",
    "            f\"{ga_results['n_selected']}/{len(feature_names)}\",\n",
    "            f\"{(1 - ga_results['n_selected']/len(feature_names))*100:.2f}\",\n",
    "            f\"{ga_results['best_fitness']:.6f}\",\n",
    "            len(ga_results['fitness_history'])\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Comparison in terms of accuracy\n",
    "\n",
    "    if pso_results['final_accuracy'] > ga_results['final_accuracy']:\n",
    "        diff = (pso_results['final_accuracy'] - ga_results['final_accuracy']) * 100\n",
    "        print(f\"PSO has better accuracy (Difference: {diff:.2f}%)\")\n",
    "    elif ga_results['final_accuracy'] > pso_results['final_accuracy']:\n",
    "        diff = (ga_results['final_accuracy'] - pso_results['final_accuracy']) * 100\n",
    "        print(f\"GA has better accuracy (Difference: {diff:.2f}%)\")\n",
    "    else:\n",
    "        print(\"The accuracy of both algorithms is equal\")\n",
    "    \n",
    "    # Comparison in terms of model simplicity\n",
    "\n",
    "    if pso_results['n_selected'] < ga_results['n_selected']:\n",
    "        diff = ga_results['n_selected'] - pso_results['n_selected']\n",
    "        print(f\"PSO created a simpler model ({diff} fewer features)\")\n",
    "    elif ga_results['n_selected'] < pso_results['n_selected']:\n",
    "        diff = pso_results['n_selected'] - ga_results['n_selected']\n",
    "        print(f\"GA created a simpler model ({diff} fewer features)\")\n",
    "    else:\n",
    "        print(\"Both algorithms selected the same number of features\")\n",
    "    \n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "comparison_table = compare_algorithms(pso_results, ga_results, X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7efc5",
   "metadata": {},
   "source": [
    "## Analysis of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcda6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
